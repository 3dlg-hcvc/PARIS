<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description" content="PARIS: Part-level Reconstruction and Motion Analysis for Articulated Objects.">
  <meta name="keywords" content="PARIS, NeRF, Articulated Objects">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <title>PARIS: Part-level Reconstruction and Motion Analysis for Articulated Objects</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <!-- <link rel="icon" href="./static/images/favicon.svg"> -->

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>

<body>

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">PARIS: Part-level Reconstruction and Motion Analysis for
              Articulated Objects</h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="">Jiayi Liu</a>,</span>
              <span class="author-block">
                <a href="https://www.sfu.ca/~amahdavi/">Ali Mahdavi-Amiri</a>,</span>
              <span class="author-block">
                <a href="https://msavva.github.io/">Manolis Savva</a>
              </span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block">Simon Fraser University</span>
            </div>
            <div class="is-size-5 publication-authors">
              <span class="author-block" style="color:#efcc3e">ICCV 2023</span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- PDF Link. -->
                <!-- <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span> -->
                <span class="link-block">
                  <a href="" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>
                <!-- Video Link. -->
                <span class="link-block">
                  <a href="https://youtu.be/tDSrROPCgUc" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-youtube"></i>
                    </span>
                    <span>Video</span>
                  </a>
                </span>
                <!-- Code Link. -->
                <span class="link-block">
                  <a href="https://github.com/3dlg-hcvc/paris"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
                <!-- Dataset Link. -->
                <!-- <span class="link-block">
                <a href="https://aspis.cmpt.sfu.ca/projects/paris/dataset.zip"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
              </span> -->
              </div>

            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="column has-text-centered">
        <img src="./static/images/teaser.png" class="interpolation-image" alt="Teaser." / style="max-width: 83%;">
      </div>
    </div>
  </section>

  <!-- 
<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/steve.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/chair-tp.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-shiba">
          <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/shiba.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/fullbody.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-blueshirt">
          <video poster="" id="blueshirt" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/blueshirt.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-mask">
          <video poster="" id="mask" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/mask.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-coffee">
          <video poster="" id="coffee" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/coffee.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-toby">
          <video poster="" id="toby" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/toby2.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section> -->


  <section class="section">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              We address the task of simultaneous part-level reconstruction and motion parameter estimation for
              articulated objects.
              Given two sets of multi-view images of an object in two static articulation states,
              we decouple the movable part from the static part and reconstruct shape and appearance while predicting
              the motion parameters.
            </p>
            <p>
              To tackle this problem, we present PARIS: a self-supervised,
              end-to-end architecture that learns part-level implicit shape and appearance models
              and optimizes motion parameters jointly without any 3D supervision, motion, or semantic annotation.
            </p>
            <p>
              Our experiments show that our method generalizes better across object categories, and outperforms
              baselines and prior work that are given 3D point clouds as input.
              Our approach improves reconstruction relative to state-of-the-art baselines with a Chamfer-L1 distance
              reduction of
              3.94 (45.2%) for objects and 26.79 (84.5%) for parts, and achieves 5\% error rate for motion estimation
              across 10 object categories.
            </p>
          </div>
        </div>
      </div>
      <!--/ Abstract. -->

      <!-- Paper video. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Video</h2>
          <div class="publication-video">
            <iframe src="https://www.youtube.com/embed/tDSrROPCgUc?rel=0&showinfo=0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
      <!--/ Paper video. -->
    </div>
  </section>


  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        
        <div class="column is-full-width">
          <div class="content has-text-justified">
            <h3 class="title is-3">Methods Overview</h3>
            <img src="./static/images/pipeline.png" class="interpolation-image" alt="Interpolation end reference image." />
          </div>
          <!-- Methods. -->

          <!-- Reconstruction. -->
          <div class="content has-text-justified">
            <h3 class="title is-3">Reconstruction and Motion Estimation</h3>
            <p>
              Observing an object in two articulated states from multi-view RGB images, our PARIS can produce part-level
              reconstruction and motion estimation
              without any 3D supervision or motion annotation during training.
            </p>
            <p>
            Here we show some comparison with the most-related work
            <a href="https://ut-austin-rpl.github.io/Ditto/">Ditto</a>
            who consumes a pair of 3D point clouds as input.
            </p>
            <img src="./static/images/recon.png" class="interpolation-image" alt="Interpolation end reference image." />
            <p>
              Our methods can be easily applied to real scenarios that take real photos from multi-view as input.
            </p>
            <img src="./static/images/real.png" class="interpolation-image" alt="Interpolation end reference image." />
          </div>
        </div>
        <!--/ Reconstruction. -->

      </div>

      <div>
        <h3 class="title is-3">States Interpolation</h3>
        <p>
          We can also animate the objects to other unseen states for both shape and appearance by manipulating the motion parameters we estimated.
          Here we show the rendering results from an arbitrary novel view. 
        </p>
      </div>
      <div class="column content has-text-justified">
      <img src="./static/images/gif_grid.gif" alt="animation of interpolation"/>
      </div>
      <!--/ Interpolating. -->
    </div>
  </section>


  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>
        @article{jiayi2023paris,
          author    = {Liu, Jiayi and Mahdavi-Amiri, Ali and Savva, Manolis},
          title     = {PARIS: PARIS: Part-level Reconstruction and Motion Analysis for Articulated Objects},
          year      = {2023},
        }
      </code></pre>
    </div>
  </section>


  <footer class="footer">
    <div class="container">
      <div class="content has-text-centered">
        <a class="icon-link" href="">
          <i class="fas fa-file-pdf"></i>
        </a>
        <a class="icon-link" href="https://github.com/3dlg-hcvc/paris" class="external-link" disabled>
          <i class="fab fa-github"></i>
        </a>
      </div>
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              This website is licensed under a <a rel="license"
                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
                Commons Attribution-ShareAlike 4.0 International License</a>.
              The template is borrowed from <a href="https://nerfies.github.io/">Nerfies</a>.
              Please check out their great work if you find it helpful as well.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>

</body>

</html>