name: d2nerf_misalign
tag: 'every1-initang'
seed: 42
source: sapien/foldingchair/100520
exp_dir: ./exp/${source}/${name}
runs_dir: ./runs/${source}/${name}

dataset:
  name: my_d2nerf
  scene: 103111
  root_dir: ./load/${source}/
  img_wh:
    - 800
    - 800
  train_scale: 1.0
  val_scale: 0.2
  test_scale: 1.0
  pred_scale: 1.0
  near_plane: 2.0
  far_plane: 6.0
  white_bkgd: true
  spheric_poses: false
  use_pixel_centers: true
  train_split: 'train'
  val_split: 'val'
  test_split: 'test'
  pred_split: 'pred'
  view_idx: '0003' # the view for prediction
  perturb_cam: false # if we want to perturb the camera
  misalign: true
  std_angle: 3     # the std of the perturb angle in degrees
  std_dist: 0.0     # the std of the translational error

model:
  name: d2nerf_misalign
  radius: 1.5
  init_angle: 0.1
  motion_gt: false
  motion_init_gt: false
  field_init_gt: false
  ignore_translate: true
  motion_gt_path: ./data/${source}/textured_objs/trans.json
  render_step_size: 5.e-3
  num_samples_per_ray: 1024
  train_num_rays: 256
  max_train_num_rays: 1024
  grid_prune: false
  grid_warmup: 20000
  dynamic_ray_sampling: true
  batch_image_sampling: true
  randomized: true
  ray_chunk: 4096
  white_bkgd: true
  use_maximum: false
  use_distortion: false
  use_swi: false
  use_intersect: false
  ray_marching:
    alpha_thre: 0.
    early_stop_eps: 0.
  comp_rendering:
    alpha_thre: 0.
    early_stop_eps: 0.
  geometry:
    name: volume-density
    radius: ${model.radius}
    feature_dim: 16
    raw_noise_std: 0.
    density_activation: trunc_exp
    density_bias: -1
    isosurface:
      method: mc
      resolution: 512
      chunk: 2097152
      threshold: 10.0
    xyz_encoding_config:
      otype: HashGrid
      n_levels: 16
      n_features_per_level: 2
      log2_hashmap_size: 19
      base_resolution: 16
      per_level_scale: 1.447269237440378  
    mlp_network_config:
      otype: FullyFusedMLP
      activation: ReLU
      output_activation: none
      n_neurons: 64
      n_hidden_layers: 1
  texture:
    name: volume-radiance
    input_feature_dim: ${model.geometry.feature_dim}
    dir_encoding_config:
      otype: SphericalHarmonics
      degree: 4    
    mlp_network_config:
      otype: FullyFusedMLP
      activation: ReLU
      output_activation: Sigmoid
      n_neurons: 64
      n_hidden_layers: 2
  
system:
  name: d2nerf_misalign-system
  save_volume: false # deprecated
  volume_res: 64 # deprecated
  second_stage: 100
  loss:
    lambda_rgb: 1.
    lambda_opaque: 0. # deprecated
    lambda_blend_ratio: 0.000
    lambda_distortion: 0. # deprecated
    lambda_weights: 0.000 # deprecated
    lambda_min_alpha: 0.0 # deprecated
    lambda_mask: 0.1
    lambda_swipe_ratio: 0.0
    lambda_inter_ratio: 0.0 # deprecated
  model_optimizer:
    name: Adam
    args:
      lr: 0.002
      betas: [0.9, 0.99]
      eps: 1.e-15
    params:
      static_geometry:
          lr: ${system.model_optimizer.args.lr}
      static_texture:
          lr: ${system.model_optimizer.args.lr}
      dynamic_geometry:
          lr: ${system.model_optimizer.args.lr}
      dynamic_texture:
          lr: ${system.model_optimizer.args.lr}
  motion_optimizer:
    name: Adam
    args:
      lr: 0.01
      betas: [0.9, 0.99]
      eps: 1.e-15
    params:
      axis_o:
          lr: ${system.motion_optimizer.args.lr}
      quaternions:
          lr: ${system.motion_optimizer.args.lr}
  align_optimizer:
    name: Adam
    args:
      lr: 0.005
      betas: [0.9, 0.99]
      eps: 1.e-15
    params:
      align_R_q:
          lr: ${system.align_optimizer.args.lr}
      align_t:
          lr: ${system.align_optimizer.args.lr}
  model_scheduler:
    name: MultiStepLR
    interval: step
    args:
      milestones: [10000, 15000, 18000, 20000, 25000]
      gamma: 0.5
  motion_scheduler:
    name: MultiStepLR
    interval: step
    args:
      milestones: [5000, 10000, 15000, 18000, 20000, 25000]
      gamma: 0.33
      # gamma: 0.9998848773724686
      # gamma: 1.0
  align_scheduler:
    name: MultiStepLR
    interval: step
    args:
      milestones: [8000, 10000, 15000, 18000, 20000, 25000]
      gamma: 0.33
    # name: SequentialLR
    # interval: step
    # milestones:
    #       - 50
    # schedulers:
    #   - name: LinearLR # linear warm-up in the first system.warmup_steps steps
    #     args:
    #       start_factor: 0.1
    #       end_factor: 1.0
    #       total_iters: 50
    #   - name: ExponentialLR
    #     args:
    #       gamma: 0.9998848773724686

checkpoint:
  save_top_k: -1
  every_n_train_steps: 10000

trainer:
  fast_dev_run: false
  max_steps: 10000  # the step is global_step (optim step), so the actual step is half if w/ two optim
  log_every_n_steps: 100
  num_sanity_val_steps: 0
  val_check_interval: 500
  limit_train_batches: 1.0
  limit_val_batches: 3
  enable_progress_bar: true 
  precision: 16
